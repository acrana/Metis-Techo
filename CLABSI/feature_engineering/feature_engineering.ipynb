{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930947ab-a503-43bb-b983-6f87f64f40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def connect_db():\n",
    "    \"\"\"Establish database connection to MIMIC IV\"\"\"\n",
    "    try:\n",
    "        engine = create_engine('****')\n",
    "        print(\"Successfully connected to MIMIC IV database!\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Connection failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_clabsi_cohort(engine):\n",
    "    \"\"\"\n",
    "    Get validated CLABSI cases with enhanced organism classification\n",
    "    and culture validation criteria.\n",
    "    \"\"\"\n",
    "    clabsi_query = text(\"\"\"\n",
    "    WITH clabsi_icd AS (\n",
    "        SELECT DISTINCT hadm_id, MIN(icd_code) as icd_code\n",
    "        FROM mimiciv_hosp.diagnoses_icd\n",
    "        WHERE icd_code IN ('99931', '99932', 'T80211A')\n",
    "        GROUP BY hadm_id\n",
    "    ),\n",
    "    microbe_classifications AS (\n",
    "        SELECT \n",
    "            m.hadm_id,\n",
    "            m.charttime,\n",
    "            m.org_name,\n",
    "            COUNT(*) OVER (\n",
    "                PARTITION BY m.hadm_id, m.org_name\n",
    "            ) as cultures_of_org,\n",
    "            COUNT(*) OVER (\n",
    "                PARTITION BY m.hadm_id, \n",
    "                DATE_TRUNC('day', m.charttime),\n",
    "                m.org_name\n",
    "            ) as daily_org_cultures,\n",
    "            CASE\n",
    "                -- New microbe filter: exclude common contaminants unless >=2 cultures\n",
    "                WHEN m.org_name IN ('Bacillus species', 'Micrococcus species')\n",
    "                     AND COUNT(*) OVER (\n",
    "                         PARTITION BY m.hadm_id, \n",
    "                         DATE_TRUNC('day', m.charttime),\n",
    "                         m.org_name\n",
    "                     ) < 2 THEN 'Contaminant'\n",
    "                \n",
    "                -- Rest of existing classification logic\n",
    "                WHEN m.org_name IN (\n",
    "                    'STAPH AUREUS COAG +', 'ESCHERICHIA COLI',\n",
    "                    'KLEBSIELLA PNEUMONIAE', 'PSEUDOMONAS AERUGINOSA',\n",
    "                    'ENTEROCOCCUS FAECIUM', 'CANDIDA ALBICANS'\n",
    "                ) THEN 'Primary Pathogen'\n",
    "                \n",
    "                WHEN m.org_name IN (\n",
    "                    'STAPHYLOCOCCUS, COAGULASE NEGATIVE',\n",
    "                    'STAPHYLOCOCCUS EPIDERMIDIS'\n",
    "                ) AND COUNT(*) OVER (\n",
    "                    PARTITION BY m.hadm_id, \n",
    "                    DATE_TRUNC('day', m.charttime),\n",
    "                    m.org_name\n",
    "                ) >= 2 THEN 'Validated Common Contaminant'\n",
    "                \n",
    "                WHEN m.org_name LIKE 'CANDIDA%' OR\n",
    "                     m.org_name IN (\n",
    "                        'ENTEROCOCCUS FAECALIS',\n",
    "                        'SERRATIA MARCESCENS',\n",
    "                        'BACTEROIDES FRAGILIS GROUP'\n",
    "                     ) THEN 'Other Pathogen'\n",
    "                ELSE 'Requires Review'\n",
    "            END as organism_classification\n",
    "        FROM mimiciv_hosp.microbiologyevents m\n",
    "        WHERE m.spec_type_desc = 'BLOOD CULTURE'\n",
    "        AND m.org_name IS NOT NULL\n",
    "    ),\n",
    "    validated_cases AS (\n",
    "        SELECT DISTINCT\n",
    "            i.subject_id,\n",
    "            i.hadm_id,\n",
    "            i.stay_id,\n",
    "            i.intime as icu_admission,\n",
    "            i.outtime as icu_discharge,\n",
    "            l.starttime as line_start,\n",
    "            l.endtime as line_end,\n",
    "            l.line_type,\n",
    "            EXTRACT(EPOCH FROM (l.endtime - l.starttime))/86400 as line_duration_days,\n",
    "            m.charttime as infection_time,\n",
    "            m.org_name,\n",
    "            m.cultures_of_org,\n",
    "            m.daily_org_cultures,\n",
    "            m.organism_classification\n",
    "        FROM mimiciv_icu.icustays i\n",
    "        INNER JOIN clabsi_icd c ON i.hadm_id = c.hadm_id\n",
    "        INNER JOIN mimiciv_derived.invasive_line l ON i.stay_id = l.stay_id\n",
    "        INNER JOIN microbe_classifications m ON i.hadm_id = m.hadm_id\n",
    "        WHERE\n",
    "            -- New line validation filter\n",
    "            l.line_type IN (\n",
    "                'PICC', 'Multi Lumen', 'Dialysis', 'Triple Introducer',\n",
    "                'Pre-Sep', 'Hickman', 'Portacath', 'Cordis/Introducer',\n",
    "                'Continuous Cardiac Output PA', 'PA'\n",
    "            )\n",
    "            AND l.line_type NOT IN ('Peripheral IV', 'Arterial Line')\n",
    "            \n",
    "            AND m.charttime > l.starttime\n",
    "            AND m.charttime <= l.starttime + INTERVAL '14 days'\n",
    "            AND EXTRACT(EPOCH FROM (l.endtime - l.starttime))/86400 >= 2\n",
    "            AND m.organism_classification IN (\n",
    "                'Primary Pathogen',\n",
    "                'Validated Common Contaminant',\n",
    "                'Other Pathogen'\n",
    "            )\n",
    "    )\n",
    "    SELECT *,\n",
    "        CASE\n",
    "            WHEN organism_classification = 'Primary Pathogen' THEN 'Confirmed CLABSI'\n",
    "            WHEN organism_classification = 'Validated Common Contaminant' \n",
    "                 AND daily_org_cultures >= 2 THEN 'Confirmed CLABSI'\n",
    "            WHEN organism_classification = 'Other Pathogen' \n",
    "                 AND cultures_of_org >= 2 THEN 'Confirmed CLABSI'\n",
    "            ELSE 'Requires Review'\n",
    "        END as clabsi_status\n",
    "    FROM validated_cases v\n",
    "    WHERE line_duration_days >= 2\n",
    "    ORDER BY stay_id, infection_time;\n",
    "    \"\"\")\n",
    "    \n",
    "    clabsi_df = pd.read_sql(clabsi_query, engine)\n",
    "    return clabsi_df\n",
    "\n",
    "# Initialize database connection and load cohort\n",
    "print(\"Loading CLABSI cohort...\")\n",
    "engine = connect_db()\n",
    "if engine:\n",
    "    clabsi_cohort = get_clabsi_cohort(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e58e93-0f6f-4213-82b7-2f745ef91236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_control_cohort(engine, clabsi_cohort, matching_ratio=4):\n",
    "    # Calculate target numbers based on unique ICU stays per line type\n",
    "    unique_stays = clabsi_cohort.drop_duplicates('stay_id')[['stay_id', 'line_type']]\n",
    "    line_targets = unique_stays['line_type'].value_counts() * matching_ratio\n",
    "    \n",
    "    control_query = text(\"\"\"\n",
    "    WITH line_patients AS (\n",
    "        -- Get all patients with qualifying central lines \n",
    "        SELECT DISTINCT\n",
    "            i.subject_id,\n",
    "            i.hadm_id,\n",
    "            i.stay_id,\n",
    "            i.intime as icu_admission,\n",
    "            i.outtime as icu_discharge,\n",
    "            l.starttime as line_start,\n",
    "            l.endtime as line_end,\n",
    "            l.line_type,\n",
    "            EXTRACT(EPOCH FROM (l.endtime - l.starttime))/86400 as line_duration_days,\n",
    "            -- Add demographics\n",
    "            p.gender,\n",
    "            p.anchor_age + EXTRACT(EPOCH FROM adm.admittime - MAKE_TIMESTAMP(p.anchor_year, 1, 1, 0, 0, 0))/31556908.8 AS admission_age,\n",
    "            adm.race,\n",
    "            adm.admission_type\n",
    "        FROM mimiciv_icu.icustays i\n",
    "        INNER JOIN mimiciv_derived.invasive_line l \n",
    "            ON i.stay_id = l.stay_id\n",
    "        INNER JOIN mimiciv_hosp.admissions adm \n",
    "            ON i.hadm_id = adm.hadm_id\n",
    "        INNER JOIN mimiciv_hosp.patients p\n",
    "            ON i.subject_id = p.subject_id\n",
    "        WHERE l.line_type IN (\n",
    "            'PICC', 'Multi Lumen', 'Dialysis', 'Triple Introducer',\n",
    "            'Pre-Sep', 'Hickman', 'Portacath', 'Cordis/Introducer',\n",
    "            'Continuous Cardiac Output PA', 'PA'\n",
    "        )\n",
    "        AND EXTRACT(EPOCH FROM (l.endtime - l.starttime))/86400 >= 2\n",
    "    ),\n",
    "    excluded_patients AS (\n",
    "        -- Exclude CLABSI cases and positive cultures\n",
    "        SELECT DISTINCT p.stay_id\n",
    "        FROM line_patients p\n",
    "        LEFT JOIN mimiciv_hosp.diagnoses_icd d \n",
    "            ON p.hadm_id = d.hadm_id\n",
    "        LEFT JOIN mimiciv_hosp.microbiologyevents m\n",
    "            ON p.hadm_id = m.hadm_id\n",
    "            AND m.charttime BETWEEN p.line_start AND p.line_end\n",
    "        WHERE d.icd_code IN ('99931', '99932', 'T80211A')\n",
    "        OR (\n",
    "            m.spec_type_desc = 'BLOOD CULTURE'\n",
    "            AND m.org_name IS NOT NULL\n",
    "        )\n",
    "    ),\n",
    "    eligible_controls AS (\n",
    "        SELECT \n",
    "            p.*,\n",
    "            CASE \n",
    "                WHEN p.line_type = 'Multi Lumen' THEN :multi_lumen_target\n",
    "                WHEN p.line_type = 'Dialysis' THEN :dialysis_target\n",
    "                WHEN p.line_type = 'PICC' THEN :picc_target\n",
    "                WHEN p.line_type = 'PA' THEN :pa_target\n",
    "                WHEN p.line_type = 'Cordis/Introducer' THEN :cordis_target\n",
    "                WHEN p.line_type = 'Hickman' THEN :hickman_target\n",
    "                WHEN p.line_type = 'Portacath' THEN :portacath_target\n",
    "                WHEN p.line_type = 'Continuous Cardiac Output PA' THEN :cco_pa_target\n",
    "                ELSE 40\n",
    "            END as target_n,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY p.line_type \n",
    "                ORDER BY random()\n",
    "            ) as type_rank\n",
    "        FROM line_patients p\n",
    "        WHERE NOT EXISTS (\n",
    "            SELECT 1 \n",
    "            FROM excluded_patients e \n",
    "            WHERE p.stay_id = e.stay_id\n",
    "        )\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM eligible_controls\n",
    "    WHERE type_rank <= target_n\n",
    "    ORDER BY line_type, type_rank;\n",
    "    \"\"\")\n",
    "    \n",
    "    # Execute query with parameters\n",
    "    controls_df = pd.read_sql(\n",
    "        control_query, \n",
    "        engine,\n",
    "        params={\n",
    "            'multi_lumen_target': int(line_targets.get('Multi Lumen', 0)),\n",
    "            'dialysis_target': int(line_targets.get('Dialysis', 0)),\n",
    "            'picc_target': int(line_targets.get('PICC', 0)),\n",
    "            'pa_target': int(line_targets.get('PA', 0)),\n",
    "            'cordis_target': int(line_targets.get('Cordis/Introducer', 0)),\n",
    "            'hickman_target': int(line_targets.get('Hickman', 0)),\n",
    "            'portacath_target': int(line_targets.get('Portacath', 0)),\n",
    "            'cco_pa_target': int(line_targets.get('Continuous Cardiac Output PA', 0))\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nControl Cohort Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total controls: {len(controls_df)}\")\n",
    "    print(f\"Unique patients: {controls_df['subject_id'].nunique()}\")\n",
    "    print(f\"Unique ICU stays: {controls_df['stay_id'].nunique()}\")\n",
    "    \n",
    "    print(\"\\nMatching Ratios by Line Type:\")\n",
    "    unique_clabsi = unique_stays['line_type'].value_counts()\n",
    "    unique_controls = controls_df['line_type'].value_counts()\n",
    "    ratios = pd.DataFrame({\n",
    "        'CLABSI_stays': unique_clabsi,\n",
    "        'Control_stays': unique_controls,\n",
    "        'Ratio': unique_controls / unique_clabsi\n",
    "    }).round(2)\n",
    "    print(ratios)\n",
    "    \n",
    "    return controls_df\n",
    "\n",
    "# Get matched controls\n",
    "if 'clabsi_cohort' in locals():\n",
    "    control_cohort = get_control_cohort(engine, clabsi_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02b65fc-40b8-4c80-826e-1b1b8ea2539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_demographic_features(engine, cohort_df):\n",
    "    demo_query = text(\"\"\"\n",
    "    WITH demographics AS (\n",
    "        SELECT DISTINCT\n",
    "            icu.stay_id,\n",
    "            icu.hadm_id,\n",
    "            icu.subject_id,\n",
    "            -- Demographics\n",
    "            p.gender,\n",
    "            p.anchor_age + EXTRACT(EPOCH FROM adm.admittime - MAKE_TIMESTAMP(p.anchor_year, 1, 1, 0, 0, 0))/31556908.8 AS admission_age,\n",
    "            -- Simplified ethnicity grouping\n",
    "            CASE\n",
    "                WHEN adm.race LIKE '%BLACK%' OR adm.race LIKE '%AFRICAN%' THEN 'BLACK'\n",
    "                WHEN adm.race LIKE '%ASIAN%' THEN 'ASIAN'\n",
    "                WHEN adm.race LIKE '%HISPANIC%' OR adm.race LIKE '%LATINO%' THEN 'HISPANIC'\n",
    "                WHEN adm.race LIKE '%WHITE%' THEN 'WHITE'\n",
    "                ELSE 'OTHER'\n",
    "            END AS ethnicity\n",
    "        FROM mimiciv_icu.icustays icu\n",
    "        INNER JOIN mimiciv_hosp.admissions adm \n",
    "            ON icu.hadm_id = adm.hadm_id\n",
    "        INNER JOIN mimiciv_hosp.patients p \n",
    "            ON icu.subject_id = p.subject_id\n",
    "        WHERE icu.stay_id IN :stay_ids\n",
    "    ),\n",
    "    comorbidities AS (\n",
    "        SELECT \n",
    "            icu.stay_id,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'I10%' OR d.icd_code LIKE '401%' THEN 1 ELSE 0 END) as has_htn,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'J44%' OR d.icd_code LIKE '496%' THEN 1 ELSE 0 END) as has_copd,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'K70%' OR d.icd_code LIKE 'K72%' OR d.icd_code LIKE 'K76%' THEN 1 ELSE 0 END) as has_liver,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'I21%' OR d.icd_code LIKE 'I22%' OR d.icd_code LIKE '410%' THEN 1 ELSE 0 END) as has_mi,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'I50%' OR d.icd_code LIKE '428%' THEN 1 ELSE 0 END) as has_chf,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'I63%' OR d.icd_code LIKE '433%' OR d.icd_code LIKE '434%' THEN 1 ELSE 0 END) as has_cva,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'C%' OR d.icd_code LIKE '14%' OR d.icd_code LIKE '20%' THEN 1 ELSE 0 END) as has_cancer,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'B20%' OR d.icd_code LIKE 'B21%' OR d.icd_code LIKE '042%' THEN 1 ELSE 0 END) as has_aids,\n",
    "            MAX(CASE WHEN d.icd_code LIKE 'E11%' OR d.icd_code LIKE '250%' THEN 1 ELSE 0 END) as has_diabetes\n",
    "        FROM mimiciv_icu.icustays icu\n",
    "        LEFT JOIN mimiciv_hosp.diagnoses_icd d\n",
    "            ON icu.hadm_id = d.hadm_id\n",
    "        WHERE icu.stay_id IN :stay_ids\n",
    "        GROUP BY icu.stay_id\n",
    "    )\n",
    "    SELECT \n",
    "        d.*,\n",
    "        COALESCE(c.has_htn, 0) as has_htn,\n",
    "        COALESCE(c.has_copd, 0) as has_copd,\n",
    "        COALESCE(c.has_liver, 0) as has_liver,\n",
    "        COALESCE(c.has_mi, 0) as has_mi,\n",
    "        COALESCE(c.has_chf, 0) as has_chf,\n",
    "        COALESCE(c.has_cva, 0) as has_cva,\n",
    "        COALESCE(c.has_cancer, 0) as has_cancer,\n",
    "        COALESCE(c.has_aids, 0) as has_aids,\n",
    "        COALESCE(c.has_diabetes, 0) as has_diabetes\n",
    "    FROM demographics d\n",
    "    LEFT JOIN comorbidities c ON d.stay_id = c.stay_id\n",
    "    ORDER BY d.stay_id;\n",
    "    \"\"\")\n",
    "    \n",
    "    # Execute query with parameters\n",
    "    stay_ids = tuple(int(x) for x in cohort_df['stay_id'].unique())\n",
    "    demo_df = pd.read_sql(demo_query, engine, params={'stay_ids': stay_ids})\n",
    "    \n",
    "    # Create binary features from gender and ethnicity\n",
    "    demo_df['gender'] = (demo_df['gender'] == 'M').astype(int)\n",
    "    demo_df = pd.get_dummies(demo_df, columns=['ethnicity'], prefix='ethnicity')\n",
    "    \n",
    "    print(\"\\nDemographic Features Summary:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Features extracted for {len(demo_df)} cases\")\n",
    "    \n",
    "    print(\"\\nNumerical Feature Statistics:\")\n",
    "    print(demo_df[['admission_age']].describe().round(2))\n",
    "    \n",
    "    print(\"\\nComorbidity Frequencies:\")\n",
    "    comorbidity_cols = [col for col in demo_df.columns if col.startswith('has_')]\n",
    "    print(demo_df[comorbidity_cols].sum().sort_values(ascending=False))\n",
    "    \n",
    "    return demo_df\n",
    "\n",
    "if 'clabsi_cohort' in locals():\n",
    "    print(\"Testing demographic feature extraction...\")\n",
    "    try:\n",
    "        demographic_features = get_demographic_features(engine, clabsi_cohort)\n",
    "        print(\"\\nShape of extracted features:\", demographic_features.shape)\n",
    "        print(\"\\nFeature names:\")\n",
    "        print(demographic_features.columns.tolist())\n",
    "        print(\"\\nMissing values summary:\")\n",
    "        print(demographic_features.isnull().sum()[demographic_features.isnull().sum() > 0])\n",
    "    except Exception as e:\n",
    "        print(\"Error during feature extraction:\", str(e))\n",
    "else:\n",
    "    print(\"Please run the CLABSI cohort creation first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c1804-2885-45d5-8438-d6713652a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_features(engine, cohort_df):\n",
    "   device_query = text(\"\"\"\n",
    "   WITH device_timing AS (\n",
    "       -- Get infection timing for each case\n",
    "       SELECT \n",
    "           icu.stay_id,\n",
    "           icu.hadm_id,\n",
    "           icu.subject_id,\n",
    "           COALESCE(\n",
    "               (SELECT MIN(charttime) \n",
    "               FROM mimiciv_hosp.microbiologyevents me \n",
    "               WHERE me.hadm_id = icu.hadm_id \n",
    "               AND me.org_name IS NOT NULL \n",
    "               AND me.spec_type_desc = 'BLOOD CULTURE'),\n",
    "               icu.outtime\n",
    "           ) as end_time\n",
    "       FROM mimiciv_icu.icustays icu\n",
    "       WHERE icu.stay_id IN :stay_ids\n",
    "   ),\n",
    "   trach_status AS (\n",
    "       -- Identify tracheostomy before infection\n",
    "       SELECT DISTINCT\n",
    "           dt.stay_id,\n",
    "           MAX(CASE WHEN \n",
    "               LOWER(ce.value) IN ('tracheostomy tube', 'trach mask')\n",
    "               AND ce.charttime < dt.end_time\n",
    "           THEN 1 ELSE 0 END) as has_tracheostomy\n",
    "       FROM device_timing dt\n",
    "       LEFT JOIN mimiciv_icu.chartevents ce ON dt.stay_id = ce.stay_id\n",
    "       LEFT JOIN mimiciv_icu.d_items di ON ce.itemid = di.itemid\n",
    "       WHERE (LOWER(di.label) LIKE '%o2%' OR LOWER(di.label) LIKE '%delivery%')\n",
    "       GROUP BY dt.stay_id\n",
    "   ),\n",
    "   ostomy_status AS (\n",
    "        -- Identify ostomies before infection using specific itemids\n",
    "        SELECT \n",
    "            dt.stay_id,\n",
    "            MAX(CASE WHEN \n",
    "                ce.itemid IN (\n",
    "                    227458,  -- Ostomy\n",
    "                    227637,  -- Ostomy Care\n",
    "                    228341,  -- Ostomy Bag\n",
    "                    228342,  -- Ostomy Output\n",
    "                    228343,  -- Ostomy Type\n",
    "                    228344,  -- Ostomy/RNWL\n",
    "                    228345,  -- Ostomy/RNTL\n",
    "                    228346,  -- Ostomy/RNY\n",
    "                    228347   -- Ostomy/ROY\n",
    "                )\n",
    "                AND ce.charttime < dt.end_time\n",
    "            THEN 1 ELSE 0 END) as has_ostomy\n",
    "        FROM device_timing dt\n",
    "        LEFT JOIN mimiciv_icu.chartevents ce \n",
    "            ON dt.stay_id = ce.stay_id\n",
    "        GROUP BY dt.stay_id\n",
    "    )\n",
    "   SELECT \n",
    "       dt.stay_id,\n",
    "       COALESCE(t.has_tracheostomy, 0) as has_tracheostomy,\n",
    "       COALESCE(o.has_ostomy, 0) as has_ostomy\n",
    "   FROM device_timing dt\n",
    "   LEFT JOIN trach_status t ON dt.stay_id = t.stay_id\n",
    "   LEFT JOIN ostomy_status o ON dt.stay_id = o.stay_id\n",
    "   ORDER BY dt.stay_id;\n",
    "   \"\"\")\n",
    "   \n",
    "   # Execute query with parameters\n",
    "   stay_ids = tuple(int(x) for x in cohort_df['stay_id'].unique())\n",
    "   device_df = pd.read_sql(device_query, engine, params={'stay_ids': stay_ids})\n",
    "   \n",
    "   print(\"\\nDevice Features Summary:\")\n",
    "   print(\"-\" * 30)\n",
    "   print(f\"Features extracted for {len(device_df)} cases\")\n",
    "   \n",
    "   print(\"\\nDevice Frequencies:\")\n",
    "   device_cols = ['has_tracheostomy', 'has_ostomy']\n",
    "   print(device_df[device_cols].sum().sort_values(ascending=False))\n",
    "   \n",
    "   return device_df\n",
    "\n",
    "# Test the function if clabsi_cohort exists\n",
    "if 'clabsi_cohort' in locals():\n",
    "   print(\"Testing device feature extraction...\")\n",
    "   try:\n",
    "       device_features = get_device_features(engine, clabsi_cohort)\n",
    "       print(\"\\nShape of extracted features:\", device_features.shape)\n",
    "       print(\"\\nFeature names:\")\n",
    "       print(device_features.columns.tolist())\n",
    "       print(\"\\nMissing values summary:\")\n",
    "       print(device_features.isnull().sum()[device_features.isnull().sum() > 0])\n",
    "   except Exception as e:\n",
    "       print(\"Error during feature extraction:\", str(e))\n",
    "else:\n",
    "   print(\"Please run the CLABSI cohort creation first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d3e04-f7be-4784-8132-c848246fc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_care(engine, cohort_df):\n",
    "    line_care_query = text(\"\"\"\n",
    "    WITH line_events AS (\n",
    "        SELECT \n",
    "            ie.stay_id,\n",
    "            ie.hadm_id,\n",
    "            il.line_type,\n",
    "            il.line_site,\n",
    "            CASE \n",
    "                WHEN LOWER(il.line_site) LIKE '%femoral%' THEN 'Femoral'\n",
    "                WHEN LOWER(il.line_site) LIKE '%subclavian%' THEN 'Subclavian'\n",
    "                WHEN LOWER(il.line_site) LIKE '%jugular%' OR LOWER(il.line_site) LIKE '%ij%' THEN 'Internal Jugular'\n",
    "                WHEN LOWER(il.line_site) LIKE '%picc%' OR LOWER(il.line_site) LIKE '%peripherally inserted%' THEN 'PICC'\n",
    "                ELSE 'Other'\n",
    "            END as site_category,\n",
    "            CASE \n",
    "                WHEN LOWER(il.line_site) LIKE '%femoral%' THEN 'High Risk'\n",
    "                WHEN LOWER(il.line_site) LIKE '%subclavian%' THEN 'Low Risk'\n",
    "                WHEN LOWER(il.line_site) LIKE '%jugular%' OR LOWER(il.line_site) LIKE '%ij%' THEN 'Moderate Risk'\n",
    "                ELSE 'Standard Risk'\n",
    "            END as risk_category,\n",
    "            il.starttime,\n",
    "            il.endtime,\n",
    "            EXTRACT(EPOCH FROM (il.endtime - il.starttime))/86400.0 as line_duration_days,\n",
    "            LEAD(il.starttime) OVER (\n",
    "                PARTITION BY ie.stay_id, il.line_type \n",
    "                ORDER BY il.starttime\n",
    "            ) as next_line_start,\n",
    "            LAG(il.endtime) OVER (\n",
    "                PARTITION BY ie.stay_id, il.line_type \n",
    "                ORDER BY il.starttime\n",
    "            ) as prev_line_end\n",
    "        FROM mimiciv_icu.icustays ie\n",
    "        INNER JOIN mimiciv_derived.invasive_line il \n",
    "            ON ie.stay_id = il.stay_id\n",
    "        WHERE ie.stay_id IN :stay_ids\n",
    "        AND il.line_type IN (\n",
    "            'PICC', 'Multi Lumen', 'Dialysis', 'Triple Introducer',\n",
    "            'Pre-Sep', 'Hickman', 'Portacath', 'Cordis/Introducer',\n",
    "            'Continuous Cardiac Output PA', 'PA'\n",
    "        )\n",
    "    ),\n",
    "    site_complications AS (\n",
    "        SELECT \n",
    "            ce.stay_id,\n",
    "            il.line_type,\n",
    "            il.line_site,\n",
    "            COUNT(CASE \n",
    "                WHEN LOWER(ce.value) LIKE '%redness%' OR LOWER(ce.value) LIKE '%erythema%' THEN 1 \n",
    "            END) as redness_count,\n",
    "            COUNT(CASE \n",
    "                WHEN LOWER(ce.value) LIKE '%drainage%' OR LOWER(ce.value) LIKE '%purulent%' OR LOWER(ce.value) LIKE '%exudate%' THEN 1 \n",
    "            END) as drainage_count,\n",
    "            COUNT(CASE \n",
    "                WHEN LOWER(ce.value) LIKE '%tender%' OR LOWER(ce.value) LIKE '%pain%' THEN 1 \n",
    "            END) as tenderness_count,\n",
    "            COUNT(CASE \n",
    "                WHEN LOWER(ce.value) LIKE '%swelling%' OR LOWER(ce.value) LIKE '%edema%' THEN 1 \n",
    "            END) as swelling_count,\n",
    "            COUNT(CASE \n",
    "                WHEN LOWER(ce.value) LIKE '%blood%' OR LOWER(ce.value) LIKE '%oozing%' THEN 1 \n",
    "            END) as bleeding_count,\n",
    "            COUNT(CASE \n",
    "                WHEN LOWER(ce.value) LIKE '%infiltrat%' OR LOWER(ce.value) LIKE '%migration%' OR LOWER(ce.value) LIKE '%dislodg%' THEN 1 \n",
    "            END) as severe_complication_count\n",
    "        FROM mimiciv_derived.invasive_line il\n",
    "        INNER JOIN mimiciv_icu.chartevents ce \n",
    "            ON il.stay_id = ce.stay_id\n",
    "            AND ce.charttime BETWEEN il.starttime AND il.endtime\n",
    "        WHERE ce.itemid IN (\n",
    "            224188, 224269, 224267, 224270, 224263, 224264, 224268, 225315\n",
    "        )\n",
    "        AND il.line_type IN (\n",
    "            'PICC', 'Multi Lumen', 'Dialysis', 'Triple Introducer',\n",
    "            'Pre-Sep', 'Hickman', 'Portacath', 'Cordis/Introducer',\n",
    "            'Continuous Cardiac Output PA', 'PA'\n",
    "        )\n",
    "        AND ce.stay_id IN :stay_ids\n",
    "        GROUP BY ce.stay_id, il.line_type, il.line_site\n",
    "    )\n",
    "    SELECT \n",
    "        le.stay_id,\n",
    "        le.line_type,\n",
    "        le.site_category,\n",
    "        le.risk_category,\n",
    "        COUNT(DISTINCT le.line_site) as unique_sites,\n",
    "        SUM(CASE WHEN le.site_category = 'Femoral' THEN 1 ELSE 0 END) as femoral_count,\n",
    "        SUM(CASE WHEN le.site_category = 'Subclavian' THEN 1 ELSE 0 END) as subclavian_count,\n",
    "        SUM(CASE WHEN le.site_category = 'Internal Jugular' THEN 1 ELSE 0 END) as ij_count,\n",
    "        SUM(CASE WHEN le.site_category = 'PICC' THEN 1 ELSE 0 END) as picc_count,\n",
    "        MIN(le.line_duration_days) as shortest_duration,\n",
    "        MAX(le.line_duration_days) as longest_duration,\n",
    "        AVG(le.line_duration_days) as avg_duration,\n",
    "        COALESCE(MAX(sc.redness_count), 0) as total_redness_events,\n",
    "        COALESCE(MAX(sc.drainage_count), 0) as total_drainage_events,\n",
    "        COALESCE(MAX(sc.tenderness_count), 0) as total_tenderness_events,\n",
    "        COALESCE(MAX(sc.swelling_count), 0) as total_swelling_events,\n",
    "        COALESCE(MAX(sc.bleeding_count), 0) as total_bleeding_events,\n",
    "        COALESCE(MAX(sc.severe_complication_count), 0) as total_severe_complications\n",
    "    FROM line_events le\n",
    "    LEFT JOIN site_complications sc \n",
    "        ON le.stay_id = sc.stay_id \n",
    "        AND le.line_type = sc.line_type\n",
    "        AND le.line_site = sc.line_site\n",
    "    GROUP BY \n",
    "        le.stay_id,\n",
    "        le.line_type,\n",
    "        le.site_category,\n",
    "        le.risk_category\n",
    "    ORDER BY \n",
    "        le.stay_id, \n",
    "        le.line_type;\n",
    "    \"\"\")\n",
    "\n",
    "    # Convert stay IDs for SQL parameterization\n",
    "    stay_ids = tuple(int(x) for x in cohort_df['stay_id'].unique())\n",
    "\n",
    "    # Execute query and return the DataFrame\n",
    "    line_care_df = pd.read_sql(line_care_query, engine, params={'stay_ids': stay_ids})\n",
    "    \n",
    "    # Print summary stats\n",
    "    print(\"\\nCentral Line Care Metrics Summary:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Total unique stays: {line_care_df['stay_id'].nunique()}\")\n",
    "    print(f\"Line types captured: {line_care_df['line_type'].nunique()}\")\n",
    "    print(\"\\nRisk Category Distribution:\")\n",
    "    print(line_care_df['risk_category'].value_counts(dropna=False))\n",
    "    \n",
    "    return line_care_df\n",
    "\n",
    "# Call the function\n",
    "line_care_df = get_line_care(engine, cohort_df)\n",
    "display(line_care_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed800f-2eb0-4895-9da1-b6eb41902b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lab_values(engine, cohort_df):\n",
    "    lab_query = text(\"\"\"\n",
    "    WITH base_labs AS (\n",
    "        -- Complete Blood Count\n",
    "        SELECT \n",
    "            ie.stay_id,\n",
    "            cb.charttime,\n",
    "            'CBC' as panel,\n",
    "            cb.wbc,\n",
    "            cb.hemoglobin,\n",
    "            cb.platelet,\n",
    "            NULL::double precision as creatinine,\n",
    "            NULL::double precision as sodium,\n",
    "            NULL::double precision as potassium,\n",
    "            NULL::double precision as chloride,\n",
    "            NULL::double precision as bicarbonate,\n",
    "            NULL::double precision as inr,\n",
    "            NULL::double precision as pt,\n",
    "            NULL::double precision as ptt\n",
    "        FROM mimiciv_icu.icustays ie\n",
    "        INNER JOIN mimiciv_derived.complete_blood_count cb\n",
    "            ON ie.subject_id = cb.subject_id\n",
    "        WHERE ie.stay_id = ANY(:stay_ids)\n",
    "            \n",
    "        UNION ALL\n",
    "        \n",
    "        -- Chemistry Panel\n",
    "        SELECT \n",
    "            ie.stay_id,\n",
    "            ch.charttime,\n",
    "            'CHEM' as panel,\n",
    "            NULL::double precision as wbc,\n",
    "            NULL::double precision as hemoglobin,\n",
    "            NULL::double precision as platelet,\n",
    "            ch.creatinine,\n",
    "            ch.sodium,\n",
    "            ch.potassium,\n",
    "            ch.chloride,\n",
    "            ch.bicarbonate,\n",
    "            NULL::double precision as inr,\n",
    "            NULL::double precision as pt,\n",
    "            NULL::double precision as ptt\n",
    "        FROM mimiciv_icu.icustays ie\n",
    "        INNER JOIN mimiciv_derived.chemistry ch\n",
    "            ON ie.subject_id = ch.subject_id\n",
    "        WHERE ie.stay_id = ANY(:stay_ids)\n",
    "            \n",
    "        UNION ALL\n",
    "        \n",
    "        -- Coagulation Panel\n",
    "        SELECT \n",
    "            ie.stay_id,\n",
    "            cg.charttime,\n",
    "            'COAG' as panel,\n",
    "            NULL::double precision as wbc,\n",
    "            NULL::double precision as hemoglobin,\n",
    "            NULL::double precision as platelet,\n",
    "            NULL::double precision as creatinine,\n",
    "            NULL::double precision as sodium,\n",
    "            NULL::double precision as potassium,\n",
    "            NULL::double precision as chloride,\n",
    "            NULL::double precision as bicarbonate,\n",
    "            cg.inr,\n",
    "            cg.pt,\n",
    "            cg.ptt\n",
    "        FROM mimiciv_icu.icustays ie\n",
    "        INNER JOIN mimiciv_derived.coagulation cg\n",
    "            ON ie.subject_id = cg.subject_id\n",
    "        WHERE ie.stay_id = ANY(:stay_ids)\n",
    "    )\n",
    "    SELECT \n",
    "        stay_id,\n",
    "        -- CBC metrics\n",
    "        MIN(wbc) as wbc_min,\n",
    "        MAX(wbc) as wbc_max,\n",
    "        AVG(wbc) as wbc_mean,\n",
    "        MIN(platelet) as plt_min,\n",
    "        MAX(platelet) as plt_max,\n",
    "        AVG(platelet) as plt_mean,\n",
    "        MIN(hemoglobin) as hgb_min,\n",
    "        MAX(hemoglobin) as hgb_max,\n",
    "        AVG(hemoglobin) as hgb_mean,\n",
    "        \n",
    "        -- Chemistry metrics\n",
    "        MIN(creatinine) as creat_min,\n",
    "        MAX(creatinine) as creat_max,\n",
    "        AVG(creatinine) as creat_mean,\n",
    "        MIN(sodium) as sodium_min,\n",
    "        MAX(sodium) as sodium_max,\n",
    "        AVG(sodium) as sodium_mean,\n",
    "        \n",
    "        -- Coagulation metrics\n",
    "        MIN(inr) as inr_min,\n",
    "        MAX(inr) as inr_max,\n",
    "        AVG(inr) as inr_mean,\n",
    "        MIN(pt) as pt_min,\n",
    "        MAX(pt) as pt_max,\n",
    "        AVG(pt) as pt_mean,\n",
    "        \n",
    "        -- Lab counts\n",
    "        COUNT(DISTINCT charttime) as lab_count,\n",
    "        SUM(CASE WHEN wbc > 12 THEN 1 ELSE 0 END) as high_wbc_count,\n",
    "        SUM(CASE WHEN wbc < 4 THEN 1 ELSE 0 END) as low_wbc_count,\n",
    "        SUM(CASE WHEN platelet < 150 THEN 1 ELSE 0 END) as low_plt_count\n",
    "    FROM base_labs\n",
    "    GROUP BY stay_id\n",
    "    ORDER BY stay_id;\n",
    "    \"\"\")\n",
    "\n",
    "    \n",
    "    stay_ids = [int(x) for x in cohort_df['stay_id'].unique()]\n",
    "    \n",
    "    \n",
    "    lab_df = pd.read_sql(lab_query, engine, params={'stay_ids': stay_ids})\n",
    "    \n",
    "    if len(lab_df) > 0:\n",
    "        print(\"\\nLaboratory Values Summary:\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Features extracted for {len(lab_df)} cases\")\n",
    "        \n",
    "        if len(lab_df) > 1:  # Only show these stats if we have multiple rows\n",
    "            print(\"\\nLab Measurement Frequencies:\")\n",
    "            print(lab_df['lab_count'].describe().round(2))\n",
    "            \n",
    "            print(\"\\nKey Lab Value Statistics:\")\n",
    "            key_metrics = ['wbc_mean', 'plt_mean', 'hgb_mean',\n",
    "                         'high_wbc_count', 'low_plt_count']\n",
    "            print(lab_df[key_metrics].describe().round(2))\n",
    "    \n",
    "    return lab_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c95a30-508c-492a-999c-23db697bb0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_severity_scores(engine, cohort_df):\n",
    "    \n",
    "    queries = {\n",
    "        'sofa': \"\"\"\n",
    "        SELECT\n",
    "            stay_id,\n",
    "            sofa AS sofa_score,\n",
    "            respiration,\n",
    "            coagulation,\n",
    "            liver,\n",
    "            cardiovascular,\n",
    "            cns,\n",
    "            renal\n",
    "        FROM mimiciv_derived.first_day_sofa\n",
    "        WHERE stay_id = ANY(:stay_ids)\n",
    "        \"\"\",\n",
    "        'apsiii': \"\"\"\n",
    "        -- Integrated APS-III SQL logic\n",
    "        WITH apsiii_cte AS (\n",
    "            SELECT\n",
    "                ie.subject_id,\n",
    "                ie.hadm_id,\n",
    "                ie.stay_id,\n",
    "                apsiii,\n",
    "                CAST(1 AS DOUBLE PRECISION) / (\n",
    "                    1 + EXP(-(-4.4360 + 0.04726 * (apsiii)))\n",
    "                ) AS apsiii_prob\n",
    "            FROM mimiciv_icu.icustays AS ie\n",
    "            LEFT JOIN mimiciv_derived.apsiii AS apsiii_table\n",
    "            ON ie.stay_id = apsiii_table.stay_id\n",
    "        )\n",
    "        SELECT * FROM apsiii_cte\n",
    "        WHERE stay_id = ANY(:stay_ids);\n",
    "        \"\"\",\n",
    "        'sapsii': \"\"\"\n",
    "        -- Integrated SAPS-II SQL logic\n",
    "        WITH sapsii_cte AS (\n",
    "            SELECT\n",
    "                s.subject_id,\n",
    "                s.hadm_id,\n",
    "                s.stay_id,\n",
    "                sapsii,\n",
    "                CAST(1 AS DOUBLE PRECISION) / (\n",
    "                    1 + EXP(-(-7.7631 + 0.0737 * (sapsii) + 0.9971 * LN(sapsii + 1)))\n",
    "                ) AS sapsii_prob\n",
    "            FROM mimiciv_derived.sapsii AS s\n",
    "        )\n",
    "        SELECT * FROM sapsii_cte\n",
    "        WHERE stay_id = ANY(:stay_ids);\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    " \n",
    "    stay_ids = [int(x) for x in cohort_df['stay_id'].unique()]\n",
    "\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "   \n",
    "    for score_type, query in queries.items():\n",
    "        try:\n",
    "            print(f\"Retrieving {score_type.upper()} scores...\")\n",
    "            results[score_type] = pd.read_sql(\n",
    "                text(query),\n",
    "                engine,\n",
    "                params={'stay_ids': stay_ids}\n",
    "            )\n",
    "            print(f\"Successfully retrieved {len(results[score_type])} rows for {score_type.upper()} scores.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving {score_type.upper()} scores: {e}\")\n",
    "            results[score_type] = None\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "severity_scores = get_all_severity_scores(engine, clabsi_cohort)\n",
    "\n",
    "if severity_scores['sofa'] is not None:\n",
    "    print(\"\\nFirst-Day SOFA Scores:\")\n",
    "    display(severity_scores['sofa'].head())\n",
    "\n",
    "if severity_scores['apsiii'] is not None:\n",
    "    print(\"\\nAPS-III Scores:\")\n",
    "    display(severity_scores['apsiii'].head())\n",
    "\n",
    "if severity_scores['sapsii'] is not None:\n",
    "    print(\"\\nSAPS-II Scores:\")\n",
    "    display(severity_scores['sapsii'].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd03c1-cd52-4a7c-b570-c2c2a3d5b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_type_risk_analysis(clabsi_cohort):\n",
    "    \"\"\"\n",
    "    Analyze total line duration instead of duration before CLABSI\n",
    "    \"\"\"\n",
    "    # Calculate total line duration\n",
    "    clabsi_cohort['line_duration_total'] = (\n",
    "        (clabsi_cohort['line_end'] - clabsi_cohort['line_start']).dt.total_seconds() / 86400\n",
    "    )\n",
    "    \n",
    "    # Remove invalid durations\n",
    "    clabsi_cohort = clabsi_cohort[clabsi_cohort['line_duration_total'] > 0]\n",
    "\n",
    "    # Group by line type\n",
    "    line_risk_summary = clabsi_cohort.groupby('line_type').agg(\n",
    "        avg_duration=('line_duration_total', 'mean'),\n",
    "        median_duration=('line_duration_total', 'median'),\n",
    "        max_duration=('line_duration_total', 'max'),\n",
    "        line_count=('line_type', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    return line_risk_summary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec039b9-8e37-473a-9164-f51d9569a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_analysis(clabsi_cohort, thresholds=[3, 5, 7, 10]):\n",
    "    if 'line_duration_before_clabsi' not in clabsi_cohort.columns:\n",
    "        clabsi_cohort['adjusted_endtime'] = clabsi_cohort[['line_end', 'infection_time']].min(axis=1)\n",
    "        clabsi_cohort['line_duration_before_clabsi'] = (\n",
    "            (clabsi_cohort['adjusted_endtime'] - clabsi_cohort['line_start']).dt.total_seconds() / 86400\n",
    "        )\n",
    "        clabsi_cohort = clabsi_cohort[clabsi_cohort['line_duration_before_clabsi'] > 0]\n",
    "\n",
    "    # Initialize result storage\n",
    "    results = []\n",
    "\n",
    "    # Perform threshold analysis for each line type\n",
    "    for line_type, group in clabsi_cohort.groupby('line_type'):\n",
    "        total_lines = len(group)\n",
    "        for threshold in thresholds:\n",
    "            exceed_count = (group['line_duration_before_clabsi'] > threshold).sum()\n",
    "            exceed_rate = exceed_count / total_lines * 100\n",
    "            results.append({\n",
    "                'line_type': line_type,\n",
    "                'threshold': threshold,\n",
    "                'exceed_count': exceed_count,\n",
    "                'total_lines': total_lines,\n",
    "                'exceed_rate': exceed_rate\n",
    "            })\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    threshold_df = pd.DataFrame(results)\n",
    "    return threshold_df\n",
    "\n",
    "# Perform threshold analysis\n",
    "thresholds = [3, 5, 7, 10]\n",
    "threshold_summary = threshold_analysis(clabsi_cohort, thresholds)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nThreshold Analysis Summary:\")\n",
    "display(threshold_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e215dc-d32f-40bb-aede-7eef04d45b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chg_bath_features(engine, cohort_df):\n",
    "    bath_query = text(\"\"\"\n",
    "    WITH bath_events AS (\n",
    "        SELECT \n",
    "            ce.stay_id,\n",
    "            ce.charttime,\n",
    "            EXTRACT(EPOCH FROM (\n",
    "                ce.charttime - LAG(ce.charttime) OVER (\n",
    "                    PARTITION BY ce.stay_id ORDER BY ce.charttime\n",
    "                )\n",
    "            ))/86400 AS days_since_last_bath\n",
    "        FROM mimiciv_icu.chartevents ce\n",
    "        INNER JOIN mimiciv_derived.invasive_line il \n",
    "            ON ce.stay_id = il.stay_id\n",
    "            AND ce.charttime BETWEEN il.starttime - INTERVAL '2 hours' \n",
    "                             AND il.endtime + INTERVAL '2 hours'\n",
    "        WHERE ce.itemid = 228137  -- CHG Bath\n",
    "    ),\n",
    "    bath_analysis AS (\n",
    "        SELECT\n",
    "            stay_id,\n",
    "            COUNT(*) AS total_baths,\n",
    "            MAX(days_since_last_bath) AS max_gap_between_baths\n",
    "        FROM bath_events\n",
    "        GROUP BY stay_id\n",
    "    )\n",
    "    SELECT \n",
    "        ba.*,\n",
    "        CASE WHEN ba.total_baths = 0 THEN 1 ELSE 0 END as no_bath_flag,\n",
    "        CASE WHEN ba.max_gap_between_baths > 3 THEN 1 ELSE 0 END as irregular_bathing\n",
    "    FROM bath_analysis ba\n",
    "    WHERE ba.stay_id IN :stay_ids\n",
    "    \"\"\")\n",
    "    \n",
    "    stay_ids = tuple(int(x) for x in cohort_df['stay_id'].unique())\n",
    "    return pd.read_sql(bath_query, engine, params={'stay_ids': stay_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04750ee8-1d84-4a5a-a792-5711c9bf694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_medications(engine, cohort_df):\n",
    "    med_query = \"\"\"\n",
    "    WITH antibiotics AS (\n",
    "        SELECT \n",
    "            stay_id,\n",
    "            COUNT(DISTINCT antibiotic) AS distinct_antibiotics,\n",
    "            COUNT(*) AS total_antibiotic_orders,\n",
    "            MAX(EXTRACT(EPOCH FROM (stoptime - starttime))/86400) AS max_antibiotic_duration\n",
    "        FROM mimiciv_derived.antibiotic\n",
    "        WHERE stay_id = ANY(%(stay_ids)s)\n",
    "        GROUP BY stay_id\n",
    "    ),\n",
    "    tpn AS (\n",
    "        SELECT \n",
    "            stay_id,\n",
    "            COUNT(*) AS tpn_orders,\n",
    "            SUM(CASE WHEN rate > 0 THEN 1 ELSE 0 END) AS tpn_days\n",
    "        FROM mimiciv_icu.inputevents\n",
    "        WHERE stay_id = ANY(%(stay_ids)s)\n",
    "        AND itemid IN (\n",
    "            226089, -- TPN\n",
    "            227690  -- Lipids\n",
    "        )\n",
    "        GROUP BY stay_id\n",
    "    ),\n",
    "    high_risk_meds AS (\n",
    "        SELECT \n",
    "            stay_id,\n",
    "            COUNT(CASE WHEN itemid IN (\n",
    "                221662, -- Vasopressors\n",
    "                221653, -- Steroids\n",
    "                221668  -- Immunosuppressants\n",
    "            ) THEN 1 ELSE NULL END) AS high_risk_med_count,\n",
    "            COUNT(DISTINCT itemid) AS distinct_high_risk_meds\n",
    "        FROM mimiciv_icu.inputevents\n",
    "        WHERE stay_id = ANY(%(stay_ids)s)\n",
    "        GROUP BY stay_id\n",
    "    )\n",
    "    SELECT \n",
    "        COALESCE(a.stay_id, t.stay_id, h.stay_id) AS stay_id,\n",
    "        COALESCE(distinct_antibiotics, 0) AS distinct_antibiotics,\n",
    "        COALESCE(total_antibiotic_orders, 0) AS total_antibiotic_orders,\n",
    "        COALESCE(max_antibiotic_duration, 0) AS max_antibiotic_duration,\n",
    "        COALESCE(tpn_orders, 0) AS tpn_orders,\n",
    "        COALESCE(tpn_days, 0) AS tpn_days,\n",
    "        COALESCE(high_risk_med_count, 0) AS high_risk_med_count,\n",
    "        COALESCE(distinct_high_risk_meds, 0) AS distinct_high_risk_meds\n",
    "    FROM antibiotics a\n",
    "    FULL OUTER JOIN tpn t ON a.stay_id = t.stay_id\n",
    "    FULL OUTER JOIN high_risk_meds h ON a.stay_id = h.stay_id\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    stay_ids = [int(x) for x in cohort_df['stay_id'].unique()]\n",
    "    \n",
    "    \n",
    "    medication_df = pd.read_sql(\n",
    "        med_query, \n",
    "        engine, \n",
    "        params={'stay_ids': stay_ids}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\"\\nMedication Features Retrieved:\")\n",
    "    print(f\"Number of rows: {len(medication_df)}\")\n",
    "    display(medication_df.head())\n",
    "    \n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    display(medication_df.describe().round(2))\n",
    "    \n",
    "    return medication_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93934385-e99b-4d37-a2cf-39cdd4319d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clinical_features(engine, cohort_df):\n",
    "    line_care_query = text(\"\"\"\n",
    "    WITH line_events AS (\n",
    "        SELECT \n",
    "            ie.stay_id,\n",
    "            il.line_type,\n",
    "            il.starttime as line_start,\n",
    "            il.endtime as line_end,\n",
    "            MAX(ce.charttime) as last_dressing_change,\n",
    "            COUNT(CASE WHEN ce.itemid = 228137 THEN 1 END) as actual_baths,\n",
    "            CEIL(EXTRACT(EPOCH FROM (il.endtime - il.starttime))/86400/2) \n",
    "                as expected_baths\n",
    "        FROM mimiciv_icu.icustays ie\n",
    "        INNER JOIN mimiciv_derived.invasive_line il \n",
    "            ON ie.stay_id = il.stay_id\n",
    "        LEFT JOIN mimiciv_icu.chartevents ce \n",
    "            ON ie.stay_id = ce.stay_id\n",
    "            AND ce.charttime BETWEEN il.starttime AND il.endtime\n",
    "        WHERE ie.stay_id IN :stay_ids\n",
    "        GROUP BY ie.stay_id, il.line_type, il.starttime, il.endtime\n",
    "    ),\n",
    "    infection_timing AS (\n",
    "        SELECT \n",
    "            i.stay_id,  -- Corrected: Get stay_id from icustays\n",
    "            MIN(m.charttime) as infection_time\n",
    "        FROM mimiciv_hosp.microbiologyevents m\n",
    "        INNER JOIN mimiciv_icu.icustays i\n",
    "            ON m.hadm_id = i.hadm_id\n",
    "            AND m.charttime BETWEEN i.intime AND i.outtime\n",
    "        WHERE m.spec_type_desc = 'BLOOD CULTURE'\n",
    "          AND m.org_name IS NOT NULL\n",
    "        GROUP BY i.stay_id\n",
    "    )\n",
    "    SELECT \n",
    "        le.stay_id,\n",
    "        le.line_type,\n",
    "        EXTRACT(EPOCH FROM (it.infection_time - le.last_dressing_change))/86400 \n",
    "            as days_since_last_dressing_change,\n",
    "        le.actual_baths / NULLIF(le.expected_baths, 0) \n",
    "            as chg_adherence_ratio,\n",
    "        EXTRACT(EPOCH FROM (le.line_end - le.line_start))/86400 \n",
    "            as line_duration_days\n",
    "    FROM line_events le\n",
    "    INNER JOIN infection_timing it \n",
    "        ON le.stay_id = it.stay_id\n",
    "    ORDER BY le.stay_id;\n",
    "    \"\"\")\n",
    "    \n",
    "    stay_ids = tuple(int(x) for x in cohort_df['stay_id'].unique())\n",
    "    line_care_df = pd.read_sql(line_care_query, engine, params={'stay_ids': stay_ids})\n",
    "    return line_care_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b0e83-4c97-4fe1-868d-91565f697792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_line_sites_clabsi_risk(engine, cohort_df, line_care_df):\n",
    "    site_query = text(\"\"\"\n",
    "    WITH line_infections AS (\n",
    "        SELECT \n",
    "            il.stay_id,\n",
    "            il.line_type,\n",
    "            il.line_site,\n",
    "            CASE WHEN il.stay_id = ANY(:clabsi_ids) THEN 1 ELSE 0 END as is_clabsi,\n",
    "            EXTRACT(EPOCH FROM (il.endtime - il.starttime))/86400 as line_duration_days\n",
    "        FROM mimiciv_derived.invasive_line il\n",
    "        WHERE il.stay_id = ANY(:clabsi_ids)\n",
    "        AND il.line_site IS NOT NULL\n",
    "        AND il.line_type NOT LIKE 'Arterial'  -- Exclude arterial lines\n",
    "        AND il.line_type IN (\n",
    "            'PICC', 'Multi Lumen', 'Dialysis', 'Triple Introducer', \n",
    "            'Pre-Sep', 'Hickman', 'Portacath', 'Cordis/Introducer',\n",
    "            'Continuous Cardiac Output PA', 'PA'\n",
    "        )\n",
    "    )\n",
    "    SELECT \n",
    "        line_type,\n",
    "        line_site,\n",
    "        COUNT(*) as total_lines,\n",
    "        SUM(is_clabsi) as clabsi_count,\n",
    "        ROUND(AVG(line_duration_days), 2) as avg_duration_days\n",
    "    FROM line_infections\n",
    "    GROUP BY line_type, line_site\n",
    "    HAVING COUNT(*) >= 5\n",
    "    ORDER BY clabsi_count DESC;\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        clabsi_ids = [int(x) for x in cohort_df['stay_id'].unique()]\n",
    "        \n",
    "        site_risk = pd.read_sql(site_query, engine, params={'clabsi_ids': clabsi_ids})\n",
    "        \n",
    "        print(\"\\nCentral Line Sites Associated with CLABSI:\")\n",
    "        print(\"-\" * 40)\n",
    "        display(site_risk)\n",
    "        \n",
    "        return site_risk\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Execute \n",
    "site_risk_df = analyze_line_sites_clabsi_risk(engine, clabsi_cohort, line_care_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c451be-2a64-4eb5-8f8a-1add12f75298",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLABSIFeatureProcessor:\n",
    "\n",
    "    def __init__(self, engine):\n",
    "        \"\"\"\n",
    "        Initialize the feature processor.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        engine : SQLAlchemy engine\n",
    "            Database connection engine\n",
    "        \"\"\"\n",
    "        self.engine = engine\n",
    "        \n",
    "        \n",
    "        self.time_windows = {\n",
    "            'short': '24 hours',\n",
    "            'medium': '48 hours',\n",
    "            'long': '72 hours'\n",
    "        }\n",
    "        \n",
    "        \n",
    "        self.duration_thresholds = [3, 5, 7, 10]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            query = \"SELECT stay_id FROM mimiciv_icu.icustays LIMIT 1\"\n",
    "            self.example_stay_id = pd.read_sql(query, self.engine)['stay_id'].iloc[0]\n",
    "        except Exception as e:\n",
    "            self.example_stay_id = None\n",
    "            print(f\"Warning: Could not set example_stay_id: {e}\")\n",
    "\n",
    "    def get_all_features(self, stay_id):\n",
    "       \n",
    "        try:\n",
    "            # Create single-row dataframe with stay_id\n",
    "            stay_df = pd.DataFrame({'stay_id': [stay_id]})\n",
    "            \n",
    "            # If this is a CLABSI case, add infection_time from clabsi_cohort\n",
    "            if 'clabsi_cohort' in globals():\n",
    "                infection_time = clabsi_cohort[clabsi_cohort['stay_id'] == stay_id]['infection_time'].iloc[0]\n",
    "                stay_df['infection_time'] = infection_time\n",
    "            else:\n",
    "                # For non-CLABSI cases, use outtime as endpoint\n",
    "                outtime_query = text(\"\"\"\n",
    "                    SELECT outtime \n",
    "                    FROM mimiciv_icu.icustays \n",
    "                    WHERE stay_id = :stay_id\n",
    "                \"\"\")\n",
    "                outtime = pd.read_sql(outtime_query, self.engine, params={'stay_id': stay_id})['outtime'].iloc[0]\n",
    "                stay_df['infection_time'] = outtime\n",
    "            \n",
    "            # Get individual feature sets\n",
    "            features = {\n",
    "                'demographics': get_demographic_features(self.engine, stay_df),\n",
    "                'devices': get_device_features(self.engine, stay_df),\n",
    "                'labs': get_lab_values(self.engine, stay_df),\n",
    "                'severity': get_all_severity_scores(self.engine, stay_df),\n",
    "                'line_care': get_line_care(self.engine, stay_df),\n",
    "                'medications': get_medications(self.engine, stay_df),\n",
    "                'clinical': get_clinical_features(self.engine, stay_df),\n",
    "                'chg_bath': get_chg_bath_features(self.engine, stay_df)\n",
    "            }\n",
    "            \n",
    "            # Store feature sets as instance variables for feature names access\n",
    "            for key, value in features.items():\n",
    "                setattr(self, f\"{key}_features\", value)\n",
    "            \n",
    "            # Combine all features\n",
    "            combined_features = self._combine_features(features)\n",
    "            \n",
    "            return combined_features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features for stay_id {stay_id}: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def get_batch_features(self, cohort_df):\n",
    "        \n",
    "        try:\n",
    "            print(f\"Processing {len(cohort_df)} stays...\")\n",
    "\n",
    "            # Get features for all stays\n",
    "            features = {\n",
    "                'demographics': get_demographic_features(self.engine, cohort_df),\n",
    "                'devices': get_device_features(self.engine, cohort_df),\n",
    "                'labs': get_lab_values(self.engine, cohort_df),\n",
    "                'severity': get_all_severity_scores(self.engine, cohort_df),\n",
    "                'line_care': get_line_care(self.engine, cohort_df),\n",
    "                'medications': get_medications(self.engine, cohort_df),\n",
    "                'clinical': get_clinical_features(self.engine, cohort_df),\n",
    "                'chg_bath': get_chg_bath_features(self.engine, cohort_df)\n",
    "            }\n",
    "            \n",
    "            # Print status of each feature set\n",
    "            for name, feature_set in features.items():\n",
    "                if feature_set is not None:\n",
    "                    print(f\"{name}: {len(feature_set)} rows\")\n",
    "                else:\n",
    "                    print(f\"{name}: None\")\n",
    "            \n",
    "            # Store feature sets as instance variables\n",
    "            for key, value in features.items():\n",
    "                setattr(self, f\"{key}_features\", value)\n",
    "            \n",
    "            # Combine features and preserve original cohort information\n",
    "            print(\"Combining features...\")\n",
    "            combined_features = self._combine_features(features)\n",
    "            if combined_features is not None:\n",
    "                # Add relevant cohort columns\n",
    "                cohort_cols = ['line_type', 'line_site', 'line_duration_days'] \n",
    "                cohort_info = cohort_df[['stay_id'] + [col for col in cohort_cols if col in cohort_df.columns]]\n",
    "                combined_features = combined_features.merge(cohort_info, on='stay_id', how='left')\n",
    "                print(f\"Final feature set: {len(combined_features)} rows\")\n",
    "                \n",
    "            return combined_features\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_batch_features: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "   # In the CLABSIFeatureProcessor class, modify _combine_features method\n",
    "    def _combine_features(self, features):\n",
    "        # Keep original line_type\n",
    "        combined = features['line_care'].merge(features['demographics'], on='stay_id')\n",
    "        \n",
    "        # Add simplified version\n",
    "        combined['line_type_simple'] = combined['line_type'].apply(\n",
    "            lambda x: 'Multi-Lumen' if 'Multi Lumen' in x \n",
    "            else 'Dialysis' if 'Dialysis' in x \n",
    "            else 'PICC' if 'PICC' in x \n",
    "            else 'Other'\n",
    "        )\n",
    "    \n",
    "    # Rest of your existing merging logic\n",
    "        try:\n",
    "            import traceback  # Add import at the top\n",
    "            \n",
    "            # Start with demographics as base\n",
    "            combined = features['demographics'].copy()\n",
    "            \n",
    "            feature_sets = {\n",
    "                'devices': features['devices'],\n",
    "                'labs': features['labs'],\n",
    "                'medications': features['medications'],\n",
    "                'clinical': features['clinical']\n",
    "            }\n",
    "            \n",
    "            # Merge straightforward feature sets\n",
    "            for name, feature_set in feature_sets.items():\n",
    "                if feature_set is not None:\n",
    "                    feature_set = feature_set[feature_set['stay_id'].isin(combined['stay_id'])]\n",
    "                    if not feature_set.empty:\n",
    "                        combined = combined.merge(feature_set, on='stay_id', how='left')\n",
    "            \n",
    "            # Handle severity scores separately\n",
    "            if features['severity'] is not None:\n",
    "                severity_scores = features['severity']\n",
    "                if severity_scores['sofa'] is not None:\n",
    "                    combined = combined.merge(severity_scores['sofa'], on='stay_id', how='left')\n",
    "                if severity_scores['apsiii'] is not None:\n",
    "                    apsiii_cols = ['stay_id', 'apsiii', 'apsiii_prob']\n",
    "                    combined = combined.merge(\n",
    "                        severity_scores['apsiii'][apsiii_cols], \n",
    "                        on='stay_id', \n",
    "                        how='left'\n",
    "                    )\n",
    "                if severity_scores['sapsii'] is not None:\n",
    "                    sapsii_cols = ['stay_id', 'sapsii', 'sapsii_prob']\n",
    "                    combined = combined.merge(\n",
    "                        severity_scores['sapsii'][sapsii_cols], \n",
    "                        on='stay_id', \n",
    "                        how='left'\n",
    "                    )\n",
    "            \n",
    "            # Handle CHG bath features\n",
    "            if features['chg_bath'] is not None:\n",
    "                chg_features = features['chg_bath']\n",
    "                chg_features = chg_features[chg_features['stay_id'].isin(combined['stay_id'])]\n",
    "                if not chg_features.empty:\n",
    "                    # Get actual columns that exist in chg_features\n",
    "                    available_cols = ['stay_id', 'total_baths']\n",
    "                    available_cols.extend([col for col in chg_features.columns \n",
    "                                        if col not in ['stay_id', 'total_baths'] \n",
    "                                        and col in chg_features.columns])\n",
    "                    \n",
    "                    combined = combined.merge(\n",
    "                        chg_features[available_cols], \n",
    "                        on='stay_id', \n",
    "                        how='left'\n",
    "                    )\n",
    "            \n",
    "            # Handle line care metrics\n",
    "            if features['line_care'] is not None:\n",
    "                line_features = features['line_care']\n",
    "                line_features = line_features[line_features['stay_id'].isin(combined['stay_id'])]\n",
    "                \n",
    "                if not line_features.empty:\n",
    "                    numeric_cols = line_features.select_dtypes(include=['float64', 'int64']).columns\n",
    "                    numeric_cols = numeric_cols[numeric_cols != 'stay_id']\n",
    "                    \n",
    "                    categorical_cols = line_features.select_dtypes(include=['object']).columns\n",
    "                    categorical_cols = categorical_cols[categorical_cols != 'stay_id']\n",
    "                    \n",
    "                    aggs = {}\n",
    "                    \n",
    "                    # Add numeric aggregations\n",
    "                    for col in numeric_cols:\n",
    "                        aggs[f\"{col}_min\"] = pd.NamedAgg(column=col, aggfunc='min')\n",
    "                        aggs[f\"{col}_max\"] = pd.NamedAgg(column=col, aggfunc='max')\n",
    "                        aggs[f\"{col}_mean\"] = pd.NamedAgg(column=col, aggfunc='mean')\n",
    "                    \n",
    "                    # Add categorical aggregations\n",
    "                    for col in categorical_cols:\n",
    "                        aggs[f\"{col}_types\"] = pd.NamedAgg(\n",
    "                            column=col,\n",
    "                            aggfunc=lambda x: '|'.join(sorted(x.unique()))\n",
    "                        )\n",
    "                    \n",
    "                    line_care_agg = line_features.groupby('stay_id').agg(**aggs).reset_index()\n",
    "                    combined = combined.merge(line_care_agg, on='stay_id', how='left')\n",
    "            \n",
    "            # Handle missing values\n",
    "            numeric_cols = combined.select_dtypes(include=['float64', 'int64']).columns\n",
    "            categorical_cols = combined.select_dtypes(include=['object']).columns\n",
    "            \n",
    "            # Fill numeric with median, excluding stay_id\n",
    "            numeric_cols = numeric_cols[numeric_cols != 'stay_id']\n",
    "            combined[numeric_cols] = combined[numeric_cols].fillna(combined[numeric_cols].median())\n",
    "            \n",
    "            # Fill categorical with mode, excluding stay_id\n",
    "            categorical_cols = categorical_cols[categorical_cols != 'stay_id']\n",
    "            for col in categorical_cols:\n",
    "                if combined[col].isnull().any():\n",
    "                    mode_value = combined[col].mode().iloc[0] if not combined[col].mode().empty else 'Unknown'\n",
    "                    combined[col] = combined[col].fillna(mode_value)\n",
    "            \n",
    "            return combined\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error combining features: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        example_features = self.get_all_features(self.example_stay_id)\n",
    "        if example_features is not None:\n",
    "            return example_features.columns.tolist()\n",
    "        return None\n",
    "        \n",
    "    def get_feature_stats(self, features_df):\n",
    "        \n",
    "        try:\n",
    "            stats = {}\n",
    "            \n",
    "            numeric_cols = features_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "            stats['numeric'] = features_df[numeric_cols].describe()\n",
    "            \n",
    "            \n",
    "            categorical_cols = features_df.select_dtypes(include=['object']).columns\n",
    "            stats['categorical'] = {\n",
    "                col: features_df[col].value_counts() \n",
    "                for col in categorical_cols\n",
    "            }\n",
    "            \n",
    "            \n",
    "            stats['missing'] = features_df.isnull().sum()\n",
    "            \n",
    "            return stats\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating feature statistics: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Test the feature processor\n",
    "if engine:\n",
    "    # Create processor instance\n",
    "    feature_processor = CLABSIFeatureProcessor(engine)\n",
    "    \n",
    "    # Test with a single stay_id from clabsi_cohort\n",
    "    print(\"Testing feature extraction with CLABSI case...\")\n",
    "    test_stay_id = clabsi_cohort['stay_id'].iloc[0]\n",
    "    features = feature_processor.get_all_features(test_stay_id)\n",
    "    \n",
    "    if features is not None:\n",
    "        print(f\"\\nExtracted {len(features.columns)} features for stay_id {test_stay_id}\")\n",
    "        \n",
    "        # Display feature categories and first few rows\n",
    "        print(\"\\nFeature sample:\")\n",
    "        display(features.head())\n",
    "        \n",
    "        # Get feature statistics\n",
    "        stats = feature_processor.get_feature_stats(features)\n",
    "        if stats:\n",
    "            print(\"\\nFeature Statistics:\")\n",
    "            display(stats['numeric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d63f61-ccb9-41ce-aee7-3dd982755493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features for both cohorts\n",
    "feature_processor = CLABSIFeatureProcessor(engine)\n",
    "\n",
    "# Process CLABSI cases with cohort info\n",
    "print(\"\\nProcessing CLABSI cohort...\")\n",
    "clabsi_features = feature_processor.get_batch_features(clabsi_cohort)\n",
    "if clabsi_features is not None:\n",
    "    clabsi_features['is_clabsi'] = 1\n",
    "\n",
    "# Process controls with cohort info \n",
    "print(\"\\nProcessing control cohort...\")\n",
    "control_features = feature_processor.get_batch_features(control_cohort)\n",
    "if control_features is not None:\n",
    "    control_features['is_clabsi'] = 0\n",
    "\n",
    "if clabsi_features is not None and control_features is not None:\n",
    "    # Combine datasets\n",
    "    combined_df = pd.concat([clabsi_features, control_features], axis=0)\n",
    "    print(f\"\\nFinal dataset shape: {combined_df.shape}\")\n",
    "    \n",
    "    from scipy.stats import ttest_ind, chi2_contingency, mannwhitneyu, fisher_exact\n",
    "    from statsmodels.stats.multitest import multipletests\n",
    "    import numpy as np\n",
    "    \n",
    "    feature_groups = {\n",
    "        'Demographics': {\n",
    "            'continuous': ['admission_age'],\n",
    "            'categorical': [col for col in combined_df.columns if col.startswith('ethnicity_')]\n",
    "        },\n",
    "        'Line Characteristics': {\n",
    "            'continuous': ['line_duration_days', 'avg_duration'],\n",
    "            'categorical': ['line_type_types', 'site_category_types', 'risk_category_types']\n",
    "        },\n",
    "        'Laboratory Values': {\n",
    "            'continuous': [col for col in combined_df.columns if any(x in col for x in ['wbc_', 'plt_', 'hgb_', 'creatinine_'])],\n",
    "            'categorical': []\n",
    "        },\n",
    "        'Care Practices': {\n",
    "            'continuous': [col for col in combined_df.columns if any(x in col for x in ['chg_bath', 'dressing_change', 'site_assessment'])],\n",
    "            'categorical': []\n",
    "        },\n",
    "        'Severity Scores': {\n",
    "            'continuous': [col for col in combined_df.columns if any(x in col for x in ['sofa', 'apsiii', 'sapsii'])],\n",
    "            'categorical': []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def analyze_features(df, feature_groups):\n",
    "        results = []\n",
    "        \n",
    "        for group_name, features in feature_groups.items():\n",
    "            print(f\"\\n{' '+group_name+' Analysis ':=^50}\")\n",
    "            \n",
    "            # Analyze continuous features\n",
    "            for feature in features['continuous']:\n",
    "                if feature in df.columns:\n",
    "                    # Check if the feature is actually numeric\n",
    "                    if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "                        clabsi_vals = df[df['is_clabsi']==1][feature].dropna()\n",
    "                        control_vals = df[df['is_clabsi']==0][feature].dropna()\n",
    "                        \n",
    "                        if len(clabsi_vals) > 0 and len(control_vals) > 0:\n",
    "                            # Calculate descriptive statistics\n",
    "                            stats = {\n",
    "                                'Feature': feature,\n",
    "                                'Group': group_name,\n",
    "                                'Type': 'continuous',\n",
    "                                'CLABSI_N': len(clabsi_vals),\n",
    "                                'Control_N': len(control_vals),\n",
    "                                'CLABSI_Mean': clabsi_vals.astype(float).mean(),\n",
    "                                'CLABSI_SD': clabsi_vals.astype(float).std(),\n",
    "                                'Control_Mean': control_vals.astype(float).mean(),\n",
    "                                'Control_SD': control_vals.astype(float).std(),\n",
    "                                'Difference': clabsi_vals.astype(float).mean() - control_vals.astype(float).mean()\n",
    "                            }\n",
    "                            \n",
    "                            # Mann-Whitney U test\n",
    "                            try:\n",
    "                                stat, p_value = mannwhitneyu(clabsi_vals.astype(float), \n",
    "                                                        control_vals.astype(float), \n",
    "                                                        alternative='two-sided')\n",
    "                                stats['P_Value'] = p_value\n",
    "                            except Exception as e:\n",
    "                                print(f\"Warning: Mann-Whitney test failed for {feature}: {str(e)}\")\n",
    "                                stats['P_Value'] = np.nan\n",
    "                                \n",
    "                            results.append(stats)\n",
    "                            \n",
    "                            print(f\"\\n{feature}\")\n",
    "                            print(f\"CLABSI (n={len(clabsi_vals)}): {stats['CLABSI_Mean']:.2f} ± {stats['CLABSI_SD']:.2f}\")\n",
    "                            print(f\"Control (n={len(control_vals)}): {stats['Control_Mean']:.2f} ± {stats['Control_SD']:.2f}\")\n",
    "                            print(f\"p-value: {stats['P_Value']:.4f}\")\n",
    "                    else:\n",
    "                        print(f\"Warning: {feature} was marked as continuous but contains non-numeric data\")\n",
    "                        # Move it to categorical if it's string data\n",
    "                        if pd.api.types.is_string_dtype(df[feature]):\n",
    "                            features['categorical'].append(feature)\n",
    "            \n",
    "            # Analyze categorical features\n",
    "            for feature in features['categorical']:\n",
    "                if feature in df.columns:\n",
    "                    contingency = pd.crosstab(df['is_clabsi'], df[feature])\n",
    "                    \n",
    "                    if contingency.shape[1] == 2:  # Binary feature\n",
    "                        try:\n",
    "                            oddsratio, p_value = fisher_exact(contingency)\n",
    "                            test_type = \"Fisher's exact test\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Warning: Fisher's exact test failed for {feature}: {str(e)}\")\n",
    "                            oddsratio, p_value = np.nan, np.nan\n",
    "                            test_type = \"Test failed\"\n",
    "                    else:\n",
    "                        try:\n",
    "                            chi2, p_value, dof, expected = chi2_contingency(contingency)\n",
    "                            oddsratio = np.nan\n",
    "                            test_type = \"Chi-square test\"\n",
    "                        except Exception as e:\n",
    "                            print(f\"Warning: Chi-square test failed for {feature}: {str(e)}\")\n",
    "                            p_value = np.nan\n",
    "                            oddsratio = np.nan\n",
    "                            test_type = \"Test failed\"\n",
    "                    \n",
    "                    stats = {\n",
    "                        'Feature': feature,\n",
    "                        'Group': group_name,\n",
    "                        'Type': 'categorical',\n",
    "                        'P_Value': p_value,\n",
    "                        'Odds_Ratio': oddsratio,\n",
    "                        'Test_Type': test_type\n",
    "                    }\n",
    "                    \n",
    "                    # Calculate proportions\n",
    "                    props = pd.crosstab(df['is_clabsi'], df[feature], normalize='index')\n",
    "                    for col in props.columns:\n",
    "                        stats[f'CLABSI_Prop_{col}'] = props.loc[1, col]\n",
    "                        stats[f'Control_Prop_{col}'] = props.loc[0, col]\n",
    "                    \n",
    "                    results.append(stats)\n",
    "                    \n",
    "                    print(f\"\\n{feature}\")\n",
    "                    print(props.round(3))\n",
    "                    print(f\"{test_type} p-value: {p_value:.4f}\")\n",
    "                    if not np.isnan(oddsratio):\n",
    "                        print(f\"Odds ratio: {oddsratio:.2f}\")\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    # Perform analysis\n",
    "    results_df = analyze_features(combined_df, feature_groups)\n",
    "    \n",
    "    # Multiple testing correction\n",
    "    p_values = results_df['P_Value'].dropna()\n",
    "    if len(p_values) > 0:\n",
    "        rejected, p_corrected, _, _ = multipletests(p_values, method='fdr_bh')\n",
    "        results_df.loc[p_values.index, 'P_Value_Adjusted'] = p_corrected\n",
    "    \n",
    "    # Sort results by significance\n",
    "    results_df = results_df.sort_values('P_Value')\n",
    "    \n",
    "    print(\"\\nSaving results...\")\n",
    "    results_df.to_csv('clabsi_analysis_results.csv', index=False)\n",
    "    print(\"Results saved to clabsi_analysis_results.csv\")\n",
    "    \n",
    "    print(\"\\nSignificant Findings (FDR-adjusted p < 0.05):\")\n",
    "    sig_results = results_df[results_df['P_Value_Adjusted'] < 0.05]\n",
    "    for _, row in sig_results.iterrows():\n",
    "        print(f\"\\n{row['Group']} - {row['Feature']}\")\n",
    "        if row['Type'] == 'continuous':\n",
    "            print(f\"CLABSI: {row['CLABSI_Mean']:.2f} ± {row['CLABSI_SD']:.2f}\")\n",
    "            print(f\"Control: {row['Control_Mean']:.2f} ± {row['Control_SD']:.2f}\")\n",
    "        else:\n",
    "            print(f\"Odds Ratio: {row['Odds_Ratio']:.2f}\")\n",
    "        print(f\"Adjusted p-value: {row['P_Value_Adjusted']:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: Failed to extract features for either CLABSI cases or controls\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
